# ExTra metric

ExTra (EXecution TRAces) is a metric for evaluating machine-generated code. Unlike most metrics, ExTra does not compare directly the generated source code with the ground truth code; instead, it executes both the generated and the ground-truth code, and compares the execution traces of these two executions. 
This repository contains an implementation of ExTra, i.e. Java and Python modules needed to (1) convert the generated code to a compilable format; (2) insert the formatted code into an executable context; (3) execute both the generated and ground-truth code; (4) collect execution traces; (5) convert the execution traces into binary vectors and (6) compute the similarity score. The repository also provides  example inputs (generated code and ground-truth code), intermediate outputs (post-processed generated code in the compilable format) and outputs (ExTra scores).

## corpora
This folder contains the parallel text-code dataset used to train the code-generated model:
* `corpus.nl` and `corpus.pl` represent the two aligned parts of the parallel dataset (text and code, respectively). This dataset was randomly divided into train set and test set (see below);
* `train.nl` and `train.pl` are the part of the corpus used for training the code-generating model;
* `test.nl` (unseen during training) was used as the input to the trained model to generate code from natural language descriptions;
* `generated_test.pl` is the code generated by the trained model based on the descriptions in `test.nl`;
* `test.pl` is the ground-truth code corresponding to the descriptions in `test.nl`;
* `meta.json` and `meta2.json` contain corpus metadata.

The details on obtaining the dataset and training the model are provided in [this paper](https://www.mdpi.com/2078-2489/10/2/66).

## extra_java
This module is the Java part of the ExTra implementation. The class `SubstituteMethods` parses the parent class of the generated function and replaces the ground truth code with the generated code. The class `DetailedReports` executes the code and collects the information about all the classes, methods and lines of code touched during the execution. `CustomCoverageBuilder` and `ProjectMapping` are utility classess referenced by `SubstituteMethods` and `DetailedReports`.

## extra_python
This is the Python part of the Extra implementation, :
* `reverse_preprocessing` - undoes tokenization and formats outputs of machine learning model so as to make the generated code compilable. Formatted examples 
* `create_project_mappings` - generates a helper file to track the location of the generated code. This file is used by the `SubstituteMethods` class and `DetailedReports' class.
* `evaluation` - for each generated piece of code, this module converts execution traces to binary vectors and calculates ExTra score (which represents the degree of similiarty between the execution vectors).
